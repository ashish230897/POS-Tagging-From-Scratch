{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad68a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1193369a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/ashish/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "802662a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'AT'), ('Fulton', 'NP-TL'), ...]\n"
     ]
    }
   ],
   "source": [
    "print(brown.tagged_words()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beb38581",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /home/ashish/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b086773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing all the POS tags, words\n",
    "tags = defaultdict()\n",
    "words = defaultdict()\n",
    "tag_words = defaultdict()\n",
    "for tuple in brown.tagged_words(tagset='universal'):\n",
    "    tag = tuple[1]\n",
    "    word = tuple[0]\n",
    "    if tag in tags: tags[tag] += 1\n",
    "    else: tags[tag] = 1\n",
    "        \n",
    "    if word in words: words[word] += 1\n",
    "    else: words[word] = 1\n",
    "        \n",
    "    if tag in tag_words:\n",
    "        if word in tag_words[tag]: tag_words[tag][word] += 1\n",
    "        else: tag_words[tag][word] = 1\n",
    "    else:\n",
    "        tag_words[tag] = defaultdict()\n",
    "        tag_words[tag][word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fecbea79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3965\n"
     ]
    }
   ],
   "source": [
    "# checking tag_words\n",
    "word = \"this\"\n",
    "tag = \"DET\"\n",
    "if word in tag_words[tag]:\n",
    "    print(tag_words[tag][word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4886a77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DET 137019\n",
      "NOUN 275558\n",
      "ADJ 83721\n",
      "VERB 182750\n",
      "ADP 144766\n",
      ". 147565\n",
      "ADV 56239\n",
      "CONJ 38151\n",
      "PRT 29829\n",
      "PRON 49334\n",
      "NUM 14874\n",
      "X 1386\n"
     ]
    }
   ],
   "source": [
    "# checking tags\n",
    "for key,value in tags.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68be0229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 7258\n",
      "Fulton 17\n",
      "County 85\n",
      "Grand 18\n",
      "Jury 4\n",
      "said 1943\n",
      "Friday 60\n",
      "an 3542\n",
      "investigation 43\n",
      "of 36080\n",
      "Atlanta's 4\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for key,value in words.items():\n",
    "    if count > 10: break\n",
    "    count += 1\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f8b992",
   "metadata": {},
   "source": [
    "## Probabilities to compute: \n",
    "    P(word|tag) = count(word,tag)/count(all words,tag) -> emission probabilities\n",
    "    P(tag1|tag2) = count(tag2,tag1)/count(tag2,tagx) -> transition probabilities\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145e9084",
   "metadata": {},
   "source": [
    "## Emission Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94b4b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing emission probabilities\n",
    "emission = defaultdict()\n",
    "for tag in tags.keys():\n",
    "    for word in words.keys():\n",
    "        \n",
    "        if tag not in emission:\n",
    "            emission[tag] = defaultdict()\n",
    "        count = 0\n",
    "        if word in tag_words[tag]: count = tag_words[tag][word]\n",
    "        emission[tag][word] = count/tags[tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d14564a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45767375327509324"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking probabilities\n",
    "tag = \"DET\"\n",
    "word = \"the\"\n",
    "emission[tag][word]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27727e7",
   "metadata": {},
   "source": [
    "## Computing bi-gram counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06030bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57340\n"
     ]
    }
   ],
   "source": [
    "sents = []\n",
    "for lis in brown.tagged_sents(tagset='universal'):\n",
    "    sents.append(lis)\n",
    "\n",
    "print(len(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ce69abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('``', '.'), ('Must', 'VERB'), ('solve', 'VERB'), ('problem', 'NOUN'), (\"''\", '.')]\n",
      "[('The', 'DET'), ('hotel', 'NOUN'), ('owner', 'NOUN'), ('shrugged', 'VERB'), ('.', '.')]\n",
      "[('Formula', 'NOUN'), ('is', 'VERB'), ('due', 'ADJ'), ('this', 'DET'), ('week', 'NOUN')]\n",
      "[('Oak', 'NOUN'), ('Grove', 'NOUN'), ('(', '.'), ('special', 'ADJ'), (')', '.')]\n",
      "[('--', '.'), ('emphasizes', 'VERB'), ('the', 'DET'), ('Virgin', 'NOUN'), ('birth', 'NOUN')]\n",
      "[(\"'\", '.'), ('church', 'NOUN'), ('meets', 'VERB'), ('change', 'NOUN'), (\"'\", '.')]\n",
      "[('Seeks', 'VERB'), ('``', '.'), ('improved', 'VERB'), ('fielding', 'VERB'), (\"''\", '.')]\n",
      "[('Duren', 'NOUN'), (',', '.'), ('Sheldon', 'NOUN'), ('on', 'ADP'), ('hill', 'NOUN')]\n",
      "[('A', 'DET'), ('quick', 'ADJ'), ('touchdown', 'NOUN'), ('resulted', 'VERB'), ('.', '.')]\n",
      "[('It', 'PRON'), ('made', 'VERB'), ('him', 'PRON'), ('human', 'NOUN'), ('.', '.')]\n",
      "[('He', 'PRON'), ('had', 'VERB'), ('a', 'DET'), ('16', 'NUM'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for sent in sents:\n",
    "    if count > 10: break\n",
    "    if len(sent) == 5: \n",
    "        print(sent)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18707287",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = defaultdict()\n",
    "for sent in sents:\n",
    "    length = len(sent)\n",
    "    for i in range(0, length-1):\n",
    "        curr = sent[i][1]\n",
    "        next_ = sent[i+1][1]\n",
    "        bi = curr + '-' + next_\n",
    "        if bi not in bigram: bigram[bi] = 1\n",
    "        else: bigram[bi] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d21ab032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4270\n",
      "275558\n"
     ]
    }
   ],
   "source": [
    "# test bi-grams\n",
    "print(bigram[\"NOUN-DET\"])\n",
    "print(tags[\"NOUN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5b112c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute bi-gram counts for starting tag and next tag\n",
    "for sent in sents:\n",
    "    start_tag = sent[0][1]\n",
    "    bi = \"^-\" + start_tag\n",
    "    if bi not in bigram: bigram[bi] = 1\n",
    "    else: bigram[bi] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc4e217",
   "metadata": {},
   "source": [
    "## Transition Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3249603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check bi-grams of states which will be divided by count of initial state\n",
    "transition = defaultdict()\n",
    "for tag in tags.keys():\n",
    "    for tag1 in tags.keys():\n",
    "        if tag not in transition:\n",
    "            transition[tag] = defaultdict()\n",
    "        transition[tag][tag1] = bigram[tag+'-'+tag1]/tags[tag] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d059a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute starting tag transition probability i.e P(X|^)\n",
    "transition[\"^\"] = defaultdict()\n",
    "for tag in tags.keys():\n",
    "     transition[\"^\"][tag] = bigram[\"^\"+\"-\"+tag]/len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52d01ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6264678621213117\n",
      "0.034339030345308684\n"
     ]
    }
   ],
   "source": [
    "# test transition\n",
    "print(transition[\"DET\"][\"NOUN\"])\n",
    "print(transition[\"^\"][\"ADJ\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4397edf",
   "metadata": {},
   "source": [
    "## Viterbi Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10fb5944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "352ab50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self, tag, prob, parent):\n",
    "        self.tag = tag\n",
    "        self.prob = prob\n",
    "        self.tags = []\n",
    "        self.parent = parent\n",
    "        \n",
    "\n",
    "class Viterbi:\n",
    "    \n",
    "    def find_tags(self, imp_nodes):\n",
    "        max_node = None\n",
    "        for tag,tag_node in imp_nodes.items():\n",
    "            if max_node is None or max_node.prob < tag_node.prob: max_node = tag_node\n",
    "        \n",
    "        tags = []\n",
    "        max_node = max_node.parent\n",
    "        while(max_node is not None):\n",
    "            tags.insert(0, max_node.tag)\n",
    "            max_node = max_node.parent\n",
    "        \n",
    "        return tags\n",
    "        \n",
    "    def compute_states(self, sent):\n",
    "        sent = sent.strip()\n",
    "        tokens = sent.split(' ')\n",
    "        if sent[-1] == \".\":\n",
    "            tokens[-1] = tokens[-1][:-1]\n",
    "            tokens.append(\".\")\n",
    "        \n",
    "        root = TreeNode(\"^\", 1, None)\n",
    "        imp_nodes = defaultdict()\n",
    "        \n",
    "        # create first level of tree\n",
    "        for tag in tags.keys():\n",
    "            node = TreeNode(tag, transition[\"^\"][tag], root)\n",
    "            root.tags.append(copy.deepcopy(node))\n",
    "            imp_nodes[tag] = copy.deepcopy(node)\n",
    "        \n",
    "        \n",
    "        temp_best = defaultdict()\n",
    "        for token in tokens:\n",
    "            level_nodes = []\n",
    "            temp_best = defaultdict()\n",
    "            for tag,tag_node in imp_nodes.items():\n",
    "                # compute every tag for this node\n",
    "                for child_tag in tags.keys():\n",
    "                    new_prob = tag_node.prob*emission[tag][token]*transition[tag][child_tag]\n",
    "                    #print(token + \" tag: \" + tag + \" child_tag: \" + child_tag + \" \" + str(new_prob))\n",
    "                    child = TreeNode(child_tag, new_prob, tag_node)\n",
    "                    tag_node.tags.append(child)\n",
    "                    level_nodes.append(child)\n",
    "            \n",
    "            # now select the best child for each tag\n",
    "            for node in level_nodes:\n",
    "                tag = node.tag\n",
    "                #print(token + \" \" + tag + \" \" + str(node.prob))\n",
    "                if tag in temp_best:\n",
    "                    if node.prob > temp_best[tag].prob:\n",
    "                        temp_best[tag] = node\n",
    "                else:\n",
    "                    temp_best[tag] = node\n",
    "            \n",
    "            for tag in tags.keys(): imp_nodes[tag] = copy.deepcopy(temp_best[tag])\n",
    "        \n",
    "        return self.find_tags(imp_nodes)\n",
    "        \n",
    "        \n",
    "\n",
    "obj = Viterbi()\n",
    "sent = \"The hotel owner shrugged.\"\n",
    "states = obj.compute_states(sent) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ea07496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['^', 'DET', 'NOUN', 'NOUN', 'VERB', '.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bdb9f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4379e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
